import os
import torch
from torch import nn, optim
from torch.utils.data import DataLoader, ConcatDataset
from models.registry import get_model
from utils.dataset import SegmentationDataset
from config import config
from losses.combo_loss import build_loss_fn
from tqdm import tqdm

# ==== å¯é…ç½®å‚æ•° ====
fine_tune_img_dir = "fix_data/images"
fine_tune_mask_dir = "fix_data/masks"
fine_tune_save_path = "checkpoints/fine_tuned.pth"
fine_tune_epochs = 5
fine_tune_lr = 1e-6
freeze_encoder = True
use_mixed_training = True  # âœ… æ˜¯å¦ä¸åŸè®­ç»ƒé›†æ··åˆè®­ç»ƒ
# ====================

def freeze_backbone_params(model):
    model_name = config["model_name"].lower()
    if "unet" in model_name:
        for name, param in model.named_parameters():
            if "down" in name or "encoder" in name:
                param.requires_grad = False
    elif "segformer" in model_name:
        for name, param in model.named_parameters():
            if "backbone" in name:
                param.requires_grad = False
    else:
        print("âš ï¸ æœªè¯†åˆ«æ¨¡å‹ç»“æ„ï¼Œæœªè¿›è¡Œå‚æ•°å†»ç»“")
    print("ğŸ§Š å·²å†»ç»“ Encoder/Backbone éƒ¨åˆ†å‚æ•°")

def train_finetune():
    device = config["device"]

    # === åŠ è½½æ¨¡å‹ ===
    model = get_model(config["model_name"],
                      in_channels=config["in_channels"],
                      out_channels=config["out_channels"]).to(device)
    model.load_state_dict(torch.load(config["save_path"], map_location=device))
    print(f"ğŸ“¦ å·²åŠ è½½æ¨¡å‹å‚æ•°: {config['save_path']}")

    if freeze_encoder:
        freeze_backbone_params(model)

    # === æ„å»ºå¾®è°ƒæ•°æ®é›† ===
    fix_dataset = SegmentationDataset(
        fine_tune_img_dir, fine_tune_mask_dir,
        image_size=config["input_size"], augment=True
    )

    if use_mixed_training:
        print("ğŸ”€ ä½¿ç”¨æ··åˆè®­ç»ƒæ¨¡å¼ï¼ˆåŸè®­ç»ƒé›† + é”™è¯¯æ ·æœ¬ï¼‰")
        train_dataset = SegmentationDataset(
            config["train_img_dir"], config["train_mask_dir"],
            image_size=config["input_size"], augment=True
        )
        total_dataset = ConcatDataset([train_dataset, fix_dataset])
    else:
        print("ğŸ§ª ä»…ä½¿ç”¨é”™è¯¯æ ·æœ¬è¿›è¡Œå¾®è°ƒ")
        total_dataset = fix_dataset

    loader = DataLoader(total_dataset, batch_size=config["batch_size"], shuffle=True)

    # === æŸå¤± & ä¼˜åŒ–å™¨ ===
    criterion = build_loss_fn(config)
    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=fine_tune_lr)

    # === å¼€å§‹å¾®è°ƒè®­ç»ƒ ===
    for epoch in range(fine_tune_epochs):
        model.train()
        total_loss = 0
        pbar = tqdm(loader, desc=f"Fine-tune Epoch {epoch+1}/{fine_tune_epochs}")
        for imgs, masks in pbar:
            imgs, masks = imgs.to(device), masks.to(device)
            preds = model(imgs)
            loss = criterion(preds, masks)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            pbar.set_postfix(loss=loss.item())

        avg_loss = total_loss / len(loader)
        print(f"âœ… Epoch {epoch+1} å¾®è°ƒå¹³å‡ Loss: {avg_loss:.4f}")

    # === ä¿å­˜å¾®è°ƒåçš„æ¨¡å‹ ===
    torch.save(model.state_dict(), fine_tune_save_path)
    print(f"âœ… å¾®è°ƒæ¨¡å‹ä¿å­˜è‡³: {fine_tune_save_path}")

if __name__ == "__main__":
    train_finetune()
