import os
import json
import numpy as np
from PIL import Image
import torch
import torchvision.transforms.functional as TF
import matplotlib.pyplot as plt

from models.registry import get_model
from config import config  # âœ… è‡ªè¡Œå‡†å¤‡ config å­—å…¸æˆ–æ¨¡å—

# ==== è·¯å¾„é…ç½® ====
IMAGE_DIR = r"C:\Users\86178\Desktop\å°å¯æ™ºèƒ½\ç„Šç‚¹ 20250630\æµ‹è¯•ç”¨å›¾"
VIS_DIR = os.path.join(IMAGE_DIR, "vis")
CORRECT_DIR = os.path.join(IMAGE_DIR, "correct")
WRONG_DIR = os.path.join(IMAGE_DIR, "wrong")
os.makedirs(VIS_DIR, exist_ok=True)
os.makedirs(CORRECT_DIR, exist_ok=True)
os.makedirs(WRONG_DIR, exist_ok=True)

device = config["device"]

# ==== åŠ è½½æ¨¡å‹ ====
model = get_model(config["model_name"], config["in_channels"], config["out_channels"]).to(device)
model.load_state_dict(torch.load(config["save_path"], map_location=device))
model.eval()

# ==== padding + crop ====
def pad_and_record(image: Image.Image, target_size):
    orig_w, orig_h = image.size
    target_w, target_h = target_size
    pad_w, pad_h = max(0, target_w - orig_w), max(0, target_h - orig_h)
    left, right = pad_w // 2, pad_w - pad_w // 2
    top, bottom = pad_h // 2, pad_h - pad_h // 2
    padded = TF.pad(image, [left, top, right, bottom], fill=0)
    return padded, (left, top, orig_w, orig_h)

def crop_back(tensor: torch.Tensor, pad_info):
    left, top, orig_w, orig_h = pad_info
    return tensor[..., top:top+orig_h, left:left+orig_w]

# ==== mask é¢„æµ‹ ====
def predict_mask(image: Image.Image):
    padded, pad_info = pad_and_record(image, config["input_size"])
    input_tensor = TF.to_tensor(padded).unsqueeze(0).to(device)
    with torch.no_grad():
        logits = model(input_tensor)[0]
        mask = torch.argmax(logits, dim=0, keepdim=True)
        cropped = crop_back(mask, pad_info)
        return cropped.squeeze(0).cpu().numpy().astype(np.uint8)

# ==== mask â†’ polygon ====
import cv2
def mask_to_shapes(mask: np.ndarray, max_points=10):
    shapes = []
    for class_id in range(1, int(mask.max()) + 1):
        binary = (mask == class_id).astype(np.uint8) * 255
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
        for cnt in contours:
            if len(cnt) >= 3:
                cnt = cnt.squeeze(1)
                if len(cnt) > max_points:
                    indices = np.linspace(0, len(cnt) - 1, max_points, dtype=int)
                    cnt = cnt[indices]
                points = [[float(x), float(y)] for x, y in cnt]
                shapes.append({
                    "label": "welding_point",
                    "points": points,
                    "group_id": None,
                    "description": "",
                    "shape_type": "polygon",
                    "flags": {},
                    "mask": None
                })
    return shapes

# ==== å¯è§†åŒ–ä¿å­˜ ====
def visualize(image: Image.Image, mask: np.ndarray, outname: str):
    fig, axs = plt.subplots(1, 3, figsize=(15, 5))
    axs[0].imshow(image, cmap='gray')
    axs[0].set_title("Input Image")
    axs[1].imshow(mask, cmap='jet')
    axs[1].set_title("Predicted Mask")
    axs[2].imshow(image, cmap='gray')
    axs[2].imshow(mask, cmap='jet', alpha=0.5)
    axs[2].set_title("Overlay")
    for ax in axs:
        ax.axis("off")
    plt.tight_layout()
    vis_path = os.path.join(VIS_DIR, f"{outname}_vis.png")
    plt.savefig(vis_path, bbox_inches='tight')
    plt.close()
    return vis_path

# ==== äººå·¥åˆ¤æ–­ç•Œé¢ ====
def show_for_review(vis_path):
    img = Image.open(vis_path)
    while True:
        plt.imshow(img)
        plt.axis("off")
        plt.title("Prediction Review\n[y] æ­£ç¡® | [n] é”™è¯¯ | [q] é€€å‡º")
        plt.show(block=False)
        key = input("ğŸ‘‰ è¯·è¾“å…¥æ ‡æ³¨ç»“æœ (y/n/q): ").strip().lower()
        plt.close()

        if key == 'y':
            return 'correct'
        elif key == 'n':
            return 'wrong'
        elif key == 'q':
            print("ğŸ‘‹ å·²é€€å‡ºäººå·¥æ ‡æ³¨")
            exit()
        else:
            print("âš ï¸ æ— æ•ˆè¾“å…¥ï¼Œè¯·é‡æ–°è¾“å…¥ï¼šyï¼ˆæ­£ç¡®ï¼‰/nï¼ˆé”™è¯¯ï¼‰/qï¼ˆé€€å‡ºï¼‰")

# ==== å•å›¾å¤„ç† ====
def process_image(image_path):
    base = os.path.splitext(os.path.basename(image_path))[0]
    json_path = os.path.join(IMAGE_DIR, base + ".json")

    image = Image.open(image_path).convert("L")
    mask = predict_mask(image)
    shapes = mask_to_shapes(mask, max_points=10)

    if not shapes:
        print(f"âŒ æ²¡æœ‰æœ‰æ•ˆè½®å»“ï¼š{base}")
        return

    json_data = {
        "version": "5.0.1",
        "flags": {},
        "shapes": shapes,
        "imagePath": os.path.basename(image_path),
        "imageData": None,
        "imageHeight": image.height,
        "imageWidth": image.width
    }

    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(json_data, f, indent=2, ensure_ascii=False)

    print(f"âœ… JSON ç”Ÿæˆï¼š{json_path}")
    vis_path = visualize(image, mask, base)

    # äººå·¥åˆ†ç±»
    result = show_for_review(vis_path)
    dest_folder = CORRECT_DIR if result == 'correct' else WRONG_DIR

    for ext in [".png", ".jpg", ".bmp", ".json"]:
        src = os.path.join(IMAGE_DIR, base + ext)
        if os.path.exists(src):
            dst = os.path.join(dest_folder, base + ext)
            os.rename(src, dst)
            print(f"â¡ï¸ ç§»åŠ¨è‡³: {dst}")

# ==== æ‰¹é‡å…¥å£ ====
if __name__ == "__main__":
    for fname in os.listdir(IMAGE_DIR):
        if fname.lower().endswith((".png", ".bmp", ".jpg")):
            process_image(os.path.join(IMAGE_DIR, fname))








r"""import os
import json
import numpy as np
from PIL import Image
import torch
import torchvision.transforms.functional as TF
import cv2

from models.registry import get_model
from config import config  # âœ… ç”¨ä½ è‡ªå·±çš„é…ç½®æ–‡ä»¶

# ==== è·¯å¾„é…ç½®ï¼ˆè‡ªåŠ¨ä» config ä¸­è¯»å–ï¼‰====
IMAGE_DIR = r"C:\Users\86178\Desktop\å°å¯æ™ºèƒ½\ç„Šç‚¹ 20250630\æµ‹è¯•ç”¨å›¾"
VIS_DIR = os.path.join(IMAGE_DIR, "vis")
os.makedirs(VIS_DIR, exist_ok=True)

device = config["device"]

# ==== æ¨¡å‹åŠ è½½ ====
model = get_model(
    config["model_name"],
    config["in_channels"],
    config["out_channels"]
).to(device)
model.load_state_dict(torch.load(config["save_path"], map_location=device))
model.eval()

# ==== padding + è®°å½•ä¿¡æ¯ ====
def pad_and_record(image: Image.Image, target_size):
    orig_w, orig_h = image.size
    target_w, target_h = target_size
    pad_w, pad_h = max(0, target_w - orig_w), max(0, target_h - orig_h)
    left, right = pad_w // 2, pad_w - pad_w // 2
    top, bottom = pad_h // 2, pad_h - pad_h // 2
    padded = TF.pad(image, [left, top, right, bottom], fill=0)
    return padded, (left, top, orig_w, orig_h)

def crop_back(tensor: torch.Tensor, pad_info):
    left, top, orig_w, orig_h = pad_info
    return tensor[..., top:top+orig_h, left:left+orig_w]

# ==== é¢„æµ‹æ©ç  ====
def predict_mask(image: Image.Image):
    padded, pad_info = pad_and_record(image, config["input_size"])
    input_tensor = TF.to_tensor(padded).unsqueeze(0).to(device)
    with torch.no_grad():
        logits = model(input_tensor)[0]
        mask = torch.argmax(logits, dim=0, keepdim=True)
        cropped = crop_back(mask, pad_info)
        return cropped.squeeze(0).cpu().numpy().astype(np.uint8)

# ==== å¤šè¾¹å½¢è½¬æ¢ + é™åˆ¶æ¯ä¸ªè½®å»“æœ€å¤š N ä¸ªç‚¹ï¼ˆç­‰é—´è·é‡‡æ ·ï¼‰ ====
def mask_to_shapes(mask: np.ndarray, max_points=10):
    shapes = []
    for class_id in range(1, int(mask.max()) + 1):
        binary = (mask == class_id).astype(np.uint8) * 255
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
        for cnt in contours:
            if len(cnt) >= 3:
                cnt = cnt.squeeze(1)
                if len(cnt) > max_points:
                    indices = np.linspace(0, len(cnt) - 1, max_points, dtype=int)
                    cnt = cnt[indices]
                points = [[float(x), float(y)] for x, y in cnt]
                shapes.append({
                    "label": "welding_point",
                    "points": points,
                    "group_id": None,
                    "description": "",
                    "shape_type": "polygon",
                    "flags": {},
                    "mask": None
                })
    return shapes

# ==== ä¸»å¤„ç†å‡½æ•° ====
def process_image(image_path):
    base = os.path.splitext(os.path.basename(image_path))[0]
    json_path = os.path.join(IMAGE_DIR, base + ".json")

    image = Image.open(image_path).convert("L")
    mask = predict_mask(image)
    shapes = mask_to_shapes(mask, max_points=10)

    if not shapes:
        print(f"âŒ æ²¡æœ‰æœ‰æ•ˆè½®å»“ï¼š{base}")
        return

    json_data = {
        "version": "5.0.1",
        "flags": {},
        "shapes": shapes,
        "imagePath": os.path.basename(image_path),
        "imageData": None,
        "imageHeight": image.height,
        "imageWidth": image.width
    }

    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(json_data, f, indent=2, ensure_ascii=False)
    print(f"âœ… JSON ç”Ÿæˆï¼š{json_path}")

# ==== æ‰¹é‡å¤„ç†å…¥å£ ====
if __name__ == "__main__":
    for fname in os.listdir(IMAGE_DIR):
        if fname.lower().endswith((".png", ".bmp", ".jpg")):
            process_image(os.path.join(IMAGE_DIR, fname))"""





r"""
import os
import json
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import torch
import torchvision.transforms.functional as TF
import cv2

from models.registry import get_model
from config import config

# ==== é…ç½®è·¯å¾„ ====
IMAGE_DIR = r"C:\Users\86178\Desktop\å°å¯æ™ºèƒ½\ç„Šç‚¹ 20250630\æµ‹è¯•ç”¨å›¾"
VIS_DIR = os.path.join(IMAGE_DIR, "vis")
os.makedirs(VIS_DIR, exist_ok=True)

device = config["device"]

# ==== åŠ è½½æ¨¡å‹ ====
model = get_model(config["model_name"], config["in_channels"], config["out_channels"]).to(device)
model.load_state_dict(torch.load(config["save_path"], map_location=device))
model.eval()

# ==== padding + è®°å½•ä¿¡æ¯ ====
def pad_and_record(image: Image.Image, target_size):
    orig_w, orig_h = image.size
    target_w, target_h = target_size
    pad_w, pad_h = max(0, target_w - orig_w), max(0, target_h - orig_h)
    left, right = pad_w // 2, pad_w - pad_w // 2
    top, bottom = pad_h // 2, pad_h - pad_h // 2
    padded = TF.pad(image, [left, top, right, bottom], fill=0)
    return padded, (left, top, orig_w, orig_h)

def crop_back(tensor: torch.Tensor, pad_info):
    left, top, orig_w, orig_h = pad_info
    return tensor[..., top:top+orig_h, left:left+orig_w]

# ==== é¢„æµ‹æ©ç  ====
def predict_mask(image: Image.Image):
    padded, pad_info = pad_and_record(image, config["input_size"])
    input_tensor = TF.to_tensor(padded).unsqueeze(0).to(device)
    with torch.no_grad():
        logits = model(input_tensor)[0]
        mask = torch.argmax(logits, dim=0, keepdim=True)
        cropped = crop_back(mask, pad_info)
        return cropped.squeeze(0).cpu().numpy().astype(np.uint8)

# ==== ç”Ÿæˆ LabelMe shapes ====
def mask_to_shapes(mask: np.ndarray):
    shapes = []
    for class_id in range(1, int(mask.max()) + 1):  # è·³è¿‡èƒŒæ™¯
        binary = (mask == class_id).astype(np.uint8) * 255
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        for cnt in contours:
            if len(cnt) >= 3:
                points = [[float(x), float(y)] for [[x, y]] in cnt]
                shapes.append({
                    "label": "welding_point",
                    "points": points,
                    "group_id": None,
                    "description": "",
                    "shape_type": "polygon",
                    "flags": {},
                    "mask": None
                })
    return shapes

# ==== å¯è§†åŒ– ====
def visualize(image: Image.Image, mask: np.ndarray, outname: str):
    fig, axs = plt.subplots(1, 3, figsize=(15, 5))
    axs[0].imshow(image, cmap='gray')
    axs[0].set_title("Input Image")
    axs[1].imshow(mask, cmap='jet')
    axs[1].set_title("Predicted Mask")
    axs[2].imshow(image, cmap='gray')
    axs[2].imshow(mask, cmap='jet', alpha=0.5)
    axs[2].set_title("Overlay")
    for ax in axs:
        ax.axis("off")
    plt.tight_layout()
    plt.savefig(os.path.join(VIS_DIR, f"{outname}_vis.png"))
    plt.close()

# ==== ä¸»å‡½æ•° ====
def process_image(image_path):
    base = os.path.splitext(os.path.basename(image_path))[0]
    json_path = os.path.join(IMAGE_DIR, base + ".json")
    if os.path.exists(json_path):
        return
    image = Image.open(image_path).convert("L")
    mask = predict_mask(image)
    shapes = mask_to_shapes(mask)
    #visualize(image, mask, base)

    if not shapes:
        print(f"âŒ æ²¡æœ‰æœ‰æ•ˆè½®å»“ï¼š{base}")
        return

    json_data = {
        "version": "5.0.1",
        "flags": {},
        "shapes": shapes,
        "imagePath": os.path.basename(image_path),
        "imageData": None,
        "imageHeight": image.height,
        "imageWidth": image.width
    }

    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(json_data, f, indent=2, ensure_ascii=False)
    print(f"âœ… JSON ç”Ÿæˆï¼š{json_path}")

# ==== æ‰¹é‡å¤„ç† ====
if __name__ == "__main__":
    for fname in os.listdir(IMAGE_DIR):
        if fname.lower().endswith((".png", ".bmp", ".jpg")):
            #process_image(os.path.join(IMAGE_DIR, fname))
    """
